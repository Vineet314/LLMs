{
    "pos_emb": "sin",
    "attn": "mha",
    "n_head": 8,
    "moe": false,
    "up_dim": 512,
    "non_linearity": "relu",
    "vocab_size": 50304,
    "block_size": 256,
    "n_embd": 128,
    "dropout": 0.3,
    "n_layer": 5,
    "norm": "layer",
    "act_recomp": false,
    "n_kv_heads": null,
    "q_latent_dim": null,
    "kv_latent_dim": null,
    "rope_head_dim": null,
    "n_exp": null,
    "n_shared": null,
    "n_act": null,
    "coeff": null,
    "aux_free": null,
    "alpha": null,
    "gamma": null
}