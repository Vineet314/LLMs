{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f1a2b7",
   "metadata": {},
   "source": [
    "### JSONL dataset format\n",
    "```jsonl\n",
    "{\"messages\": [{\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "{\"messages\": [{\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "6b0a9e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from IPython.display import Markdown\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "9e35a693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5126/5126 [00:00<00:00, 8705.61it/s] \n"
     ]
    }
   ],
   "source": [
    "# data prep\n",
    "df = pd.read_excel(\"train.xlsx\")\n",
    "df[\"parent_id\"] = df[\"parent_id\"].fillna(\"None\").astype(str)\n",
    "df[\"message_id\"] = df[\"message_id\"].astype(str)\n",
    "df[\"rank\"] = df[\"rank\"].fillna(-1).astype(int)\n",
    "len(df)\n",
    "\n",
    "children_map = defaultdict(list)\n",
    "roots = df[df[\"parent_id\"] == \"None\"]\n",
    "for _, row in df.iterrows():\n",
    "    if row[\"parent_id\"] != \"None\":\n",
    "        children_map[row[\"parent_id\"]].append(row.to_dict())\n",
    "\n",
    "def build_conversation(node, history=None):\n",
    "    if history is None:\n",
    "        history = []\n",
    "\n",
    "    # role = \"user\" if node[\"role\"] == \"prompter\" else \"assistant\"\n",
    "    history = history + [{\n",
    "        \"role\": node[\"role\"],\n",
    "        \"text\": node[\"text\"],\n",
    "        # \"rank\": int(node[\"rank\"]),\n",
    "    }]\n",
    "\n",
    "    children = children_map.get(node[\"message_id\"], [])\n",
    "    if not children:  # leaf\n",
    "        return [history]\n",
    "\n",
    "    results = []\n",
    "    for child in children:\n",
    "        results.extend(build_conversation(child, history))\n",
    "    return results\n",
    "\n",
    "examples = []\n",
    "for _, root in tqdm(roots.iterrows(), total=len(roots)):\n",
    "    examples.extend(build_conversation(root.to_dict()))\n",
    "\n",
    "with open(\"oasst2.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for convo in examples:\n",
    "        record = {\"messages\": convo}\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "47697feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29234"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"oasst2.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data:list = [json.loads(line) for line in f]\n",
    "# data_copy = deepcopy(data)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "e7869541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29234it [00:00, 2066473.69it/s]\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = {}\n",
    "i = 0\n",
    "for idx,convo in tqdm(enumerate(data)):\n",
    "    if convo['messages'][-1]['role']!='assistant':\n",
    "        x.append(convo['messages'])\n",
    "        y[f\"req_{i}\"] = idx\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "0d547b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"API_KEY\"))\n",
    "model  = 'gpt-4.1-mini'\n",
    "prompt = \"\"\"This is a multi-turn conversation which is missing the assistant's response at the end. \n",
    "Generate an appropriate assitant response STRICTLY in the JSON scehma {{'role':'assistant', 'text':'<your response here>'}}\n",
    "Output only that dictionary/json. DO NOT output any other wordings, greetings etc. Do not generate more than 600 tokens. Here is the convo:\n",
    "{x} \"\"\"\n",
    "\n",
    "with open(\"batch_in.jsonl\",\"w\", encoding='utf-8') as f:\n",
    "    for idx,miss in enumerate(x):\n",
    "        line = {\n",
    "            \"custom_id\":f\"req_{idx}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/responses\",\n",
    "            \"body\": {\n",
    "                \"model\":\"gpt-5-mini\",\n",
    "                \"reasoning\":{'effort':'minimal'},\n",
    "                \"input\":prompt.format(x=miss)}}\n",
    "        \n",
    "        f.write(json.dumps(line, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# file = client.files.create(file=open(\"batch_in.jsonl\", \"rb\"), purpose=\"batch\")\n",
    "# batch = client.batches.create(input_file_id=file.id, endpoint=\"/v1/responses\", completion_window=\"24h\")\n",
    "\n",
    "# batch_id= batch.id\n",
    "# batch = client.batches.retrieve(batch_id)\n",
    "# print(batch.status)\n",
    "# if batch.status=='completed':\n",
    "#     out_fid = batch.output_file_id\n",
    "#     out = client.files.content(out_fid)\n",
    "#     out.write_to_file(\"batch_out.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "fdf38b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"batch_out.jsonl\", 'r', encoding='utf-8') as f:\n",
    "    resp = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "614ae68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adds = {} #req_id -> addendum\n",
    "failed = []\n",
    "for res in resp:\n",
    "    id = res['custom_id']\n",
    "    try:\n",
    "        ass = eval(res['response']['body']['output'][1]['content'][0]['text'])\n",
    "        adds[id] = ass\n",
    "    except:\n",
    "        failed.append(id)\n",
    "        adds[id] = {\"role\": \"assistant\", \"content\": \"I am not sure how to help with that.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "454b2bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for req_no in range(7889):\n",
    "    req = f\"req_{req_no}\"\n",
    "    idx = y[req]\n",
    "    add = [adds[req]]\n",
    "    data[idx]['messages'].extend(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "be6ad9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.jsonl\", 'w', encoding='utf-8') as f:\n",
    "    for line in data:\n",
    "        f.write(json.dumps(line, ensure_ascii=False) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
