{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05f461cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/golem/projects/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.56.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers; transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8807073f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Activation Recomputation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LLM(\n",
       "  (tkn_emb): Embedding(50304, 1024)\n",
       "  (transformer): ModuleDict(\n",
       "    (drop): Dropout(p=0.02, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (attn): Attention(\n",
       "          (attn): GQA(\n",
       "            (c_attn): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "            (c_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ln1): LayerNorm(\n",
       "          (norm): RMSNorm((1024,), eps=None, elementwise_affine=True)\n",
       "        )\n",
       "        (ln2): LayerNorm(\n",
       "          (norm): RMSNorm((1024,), eps=None, elementwise_affine=True)\n",
       "        )\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=1024, out_features=6144, bias=False)\n",
       "          (c_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm(\n",
       "      (norm): RMSNorm((1024,), eps=None, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import LLM, LLMconfig, BlockConfig\n",
    "\n",
    "block_config = BlockConfig(\n",
    "    n_embd=1024,\n",
    "    pos_emb='rope',\n",
    "    dropout=0.2,\n",
    "    attn='gqa',\n",
    "    n_head=16,\n",
    "    moe=False,\n",
    "    up_dim=3072,\n",
    "    non_linearity='swiglu',\n",
    "    n_kv_heads=8,   \n",
    ")\n",
    "\n",
    "config = LLMconfig(\n",
    "    vocab_size=50304,\n",
    "    block_size=2048,\n",
    "    n_embd=1024,\n",
    "    pos_emb='rope',\n",
    "    dropout=0.02,\n",
    "    n_layer=12,\n",
    "    norm='rms',\n",
    "    act_recomp=True,\n",
    "    CUSTOM_LAYERS=True,\n",
    "    layer_configs=[block_config]*12\n",
    ")\n",
    "\n",
    "my_model = LLM(config)\n",
    "my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "387c0d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoModelForCausalLM\n",
    "from transformers.models.qwen3.modeling_qwen3   import Qwen3Config,  Qwen3ForCausalLM\n",
    "from transformers.models.gemma3.modeling_gemma3 import Gemma3Config, Gemma3ForCausalLM \n",
    "from transformers.models.gpt2.modeling_gpt2     import GPT2Config,   GPT2LMHeadModel\n",
    "from transformers.models.llama4.modeling_llama4 import Llama4Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce452e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qw_model:Qwen3ForCausalLM = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-0.6B\")\n",
    "qw_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c63a8c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemma3ForCausalLM(\n",
       "  (model): Gemma3TextModel(\n",
       "    (embed_tokens): Gemma3TextScaledWordEmbedding(262144, 640, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-17): 18 x Gemma3DecoderLayer(\n",
       "        (self_attn): Gemma3Attention(\n",
       "          (q_proj): Linear(in_features=640, out_features=1024, bias=False)\n",
       "          (k_proj): Linear(in_features=640, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=640, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=1024, out_features=640, bias=False)\n",
       "          (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "          (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Gemma3MLP(\n",
       "          (gate_proj): Linear(in_features=640, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=640, out_features=2048, bias=False)\n",
       "          (down_proj): Linear(in_features=2048, out_features=640, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): Gemma3RMSNorm((640,), eps=1e-06)\n",
       "        (post_attention_layernorm): Gemma3RMSNorm((640,), eps=1e-06)\n",
       "        (pre_feedforward_layernorm): Gemma3RMSNorm((640,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Gemma3RMSNorm((640,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Gemma3RMSNorm((640,), eps=1e-06)\n",
       "    (rotary_emb): Gemma3RotaryEmbedding()\n",
       "    (rotary_emb_local): Gemma3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=640, out_features=262144, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm_model:Gemma3ForCausalLM = AutoModelForCausalLM.from_pretrained(\"google/gemma-3-270m\")\n",
    "gm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8520a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oa_model:GPT2LMHeadModel = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "oa_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab86f7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Llama4TextModel(\n",
       "  (embed_tokens): Embedding(128256, 576)\n",
       "  (layers): ModuleList(\n",
       "    (0-14): 15 x Llama4TextDecoderLayer(\n",
       "      (self_attn): Llama4TextAttention(\n",
       "        (q_proj): Linear(in_features=576, out_features=576, bias=False)\n",
       "        (k_proj): Linear(in_features=576, out_features=192, bias=False)\n",
       "        (v_proj): Linear(in_features=576, out_features=192, bias=False)\n",
       "        (o_proj): Linear(in_features=576, out_features=576, bias=False)\n",
       "        (qk_norm): Llama4TextL2Norm(eps=1e-05)\n",
       "      )\n",
       "      (feed_forward): Llama4TextMLP(\n",
       "        (gate_proj): Linear(in_features=576, out_features=2048, bias=False)\n",
       "        (up_proj): Linear(in_features=576, out_features=2048, bias=False)\n",
       "        (down_proj): Linear(in_features=2048, out_features=576, bias=False)\n",
       "        (activation_fn): SiLU()\n",
       "      )\n",
       "      (input_layernorm): Llama4TextRMSNorm((576,), eps=1e-05)\n",
       "      (post_attention_layernorm): Llama4TextRMSNorm((576,), eps=1e-05)\n",
       "    )\n",
       "  )\n",
       "  (norm): Llama4TextRMSNorm((576,), eps=1e-05)\n",
       "  (rotary_emb): Llama4TextRotaryEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_model = AutoModel.from_pretrained(\"facebook/MobileLLM-R1-140M\")\n",
    "fb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43bcccb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Llama4ForCausalLM(\n",
       "  (model): Llama4TextModel(\n",
       "    (embed_tokens): Embedding(128256, 576)\n",
       "    (layers): ModuleList(\n",
       "      (0-14): 15 x Llama4TextDecoderLayer(\n",
       "        (self_attn): Llama4TextAttention(\n",
       "          (q_proj): Linear(in_features=576, out_features=576, bias=False)\n",
       "          (k_proj): Linear(in_features=576, out_features=192, bias=False)\n",
       "          (v_proj): Linear(in_features=576, out_features=192, bias=False)\n",
       "          (o_proj): Linear(in_features=576, out_features=576, bias=False)\n",
       "          (qk_norm): Llama4TextL2Norm(eps=1e-05)\n",
       "        )\n",
       "        (feed_forward): Llama4TextMLP(\n",
       "          (gate_proj): Linear(in_features=576, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=576, out_features=2048, bias=False)\n",
       "          (down_proj): Linear(in_features=2048, out_features=576, bias=False)\n",
       "          (activation_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Llama4TextRMSNorm((576,), eps=1e-05)\n",
       "        (post_attention_layernorm): Llama4TextRMSNorm((576,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): Llama4TextRMSNorm((576,), eps=1e-05)\n",
       "    (rotary_emb): Llama4TextRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=576, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fb_model = AutoModelForCausalLM.from_pretrained(\"facebook/MobileLLM-R1-140M\")\n",
    "fb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e971f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del my_model, qw_model, gm_model, oa_model, fb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0128bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qw_model_base:Qwen3ForCausalLM = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-0.6B-Base\")\n",
    "qw_model_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4c84ad0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qw_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p.numel()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[43mqw_model\u001b[49m.parameters())\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p.numel()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mqw_model_base.parameters())\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'qw_model' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"{sum(p.numel() for p in qw_model.parameters()):,}\")\n",
    "print(f\"{sum(p.numel() for p in qw_model_base.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73871b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
